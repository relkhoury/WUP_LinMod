---
title: "linear model from Web"
author: "Rabi Elkhoury"
date: "Summer 2022"
output:
   html_document:
         toc: true
         toc_depth: 5
        
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Read about the data from the website where it is staged.  Then form three regression models; Model1 is SIMS~ARM, Model2 is SIMS~GRIP, and Model3 is SIMS~ARM+GRIP. For each model find a 95% prediction interval of SIMS given a value of 94  for GRIP and 88 for ARM. Compare Model1 with Model3 using anova. Write it up in a markdown document, push the project up to your github account and submit it back to canvas as link. 

 


```{r include=FALSE}
require(tidyverse)
require(tigerstats)
require(rgl)
require(knitr)

```

```{r}
data <- read.csv(file="https://onlinestatbook.com/case_studies_rvls/physical_strength/data.txt",sep="",header=TRUE)  

```

## Model 1 SIM~ARMS

### scatterplot
```{r}
basicNN <- ggplot(data,aes(y=SIMS,x=ARM))
```
```{r}
basicNN + geom_point()
```


### Numerical results
```{r}
cor(SIMS~ARM,data=data)
```
There is a decently high correlation coefficient (r) when ARM is the explanatory variable and SIMS is the response variable.


### Inferential  (Build model.1)
```{r}
model.1 <- lm(SIMS~ARM,data=data)
summary.lm(model.1)
```
The residual standard error (1.226) is relatively low, indicating our data points are, generally, near the line of best fit.  This is further supported by the adjusted r-squared (.467) indicates that the model accounts for 46.7% of the inherent error in the system.



#### Predict at target point
```{r}
targetpoint <- data.frame(ARM = 88, GRIP = 94)
```

```{r}
predict(model.1, targetpoint, interval = "prediction")

```
The predict function applied above yielded the optimal predicted value of SIMS when inputting an ARM value of 88; the value of 94 for GRIP was negligible here.

#### scatterplot with model fit
```{r}
basicNN + geom_point() + geom_lm()
```

This scatterplot displays a strong, positive, somewhat linear relationship between ARM and SIMS; this is further corroborated by the line of best fit.  ARM seems to be moderately apt at predicting the value of


## Model 2 SIM~GRIP

### Now add in scatterplot
```{r}
basicGrip <- ggplot(data,aes(y=SIMS,x=GRIP))
```
```{r}
basicGrip + geom_point()
```

The scatterplot seems to boast a strong linear relationship, but further testing is required to see if it's a more logical model than the one explored prior.

### Numerical results 
```{r}
cor(SIMS~GRIP,data=data)
```
The correlation coefficient for Model 2 is slightly lesser than its Model 1 counterpart; this might imply that the scatterplot is a less applicable model for the question at hand.
### Inferential  (Build model.2)
```{r}
model.2 <- lm(SIMS~GRIP,data=data)
summary.lm(model.2)
```
The residual standard error for model 2 is slightly higher as compared to model 1, meaning that the range within which 95% of the data falls is somewhat larger since the value is larger (the range, determined by the two standard deviations, would turn out wider).  Finally, examining the adjusted r-squared value reveals it is lessser than model 1, implying that model 2 does a lesser job at accounting for error in the dataset.  




#### predict model.2 at target point
```{r}
targetpoint <- data.frame(ARM = 88, GRIP = 94)
```
```{r}
predict(model.2, targetpoint, interval = "prediction")

```


#### now add the model fit to our plot for model.2
```{r}
basicGrip + geom_point() + geom_lm()
```
This scatterplot relates the variables SIMS and GRIP.  Based on the earlier data calculated, along with the line of best fit generated, it is clear this is the least reliable model created thus far, since there seems to be more residual variation among the points compared to the line plotted.

## Model 3 SIM~ARM+GRIP

### Numerical results (cor)
```{r}
cor(SIMS~ARM+GRIP,data=data)
```
The correlation coefficient r for Model 3 is the highest of any model generated prior, with a value of .732.  It implies that the best explanatory variable is not ARM or GRIP, but, rather, both acting in tandem with one another.  More testing is required to confirm this.  

  
### Inferential  (Build 2-dimentional model.3)
```{r}
model.3 <- lm(SIMS~ARM+GRIP,data=data)
summary.lm(model.3)
```
When considering the inferential data for Model 3, the residual standard error is the least of any model, suggesting that the range of values that 95% of the response data fall under is constricted and closely associated; this is reinforced by the correlation coefficient.  The adjusted R-squared is .5338, the highest of any model created.  At face value, this means that 53.38% of our data's error is accounted for by Model 3.  Evidently, this means that the most accurate model generated is Model 3, since it minimizes the error generated within the dataset.



#### predict model.3 at target point
```{r}
targetpoint <- data.frame(ARM = 88, GRIP = 94)
```
```{r}
predict(model.3, targetpoint, interval = "prediction")

```
## Comparing nested models ANOVA Test

### Model.1 vs Model.3
```{r}
anova(model.1, model.3)
```
Model 3 reduced the residual standard error of model 1 by 29.45, indicating it is a more apt model compared to model 1.  P-value shows this is difference is statistically significant, since it is far less than .05.




### Model.2 vs Model.3
```{r}
anova(model.2, model.3)
```
When comparing models 2 and 3 through an ANOVA test, the Residual Sum of Squares (RSS) for model 3 is lesser than model 1; because a RSS measures the variance in a dataset, we can safely assume that model 3 is a better, dependable model.  Additionally, model 3 reduced the standard error of model 1 by 54.639, further cementing that it's a more accuarte and reliable model than the latter.




## Informally compare Model.1 with model.2





```{r}
anova(model.2, model.1)
```
